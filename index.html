<!doctype html><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>astdocs</title><meta name=title content=astdocs><meta name=description content="Extract and format Markdown documentation from Python code."><meta property=article:author content=carnarez><meta property=article:published_time content=2025-09-14><meta property=og:type content=article><meta property=og:url content=https://carnarez.github.io/astdocs><meta property=og:title content=astdocs><meta property=og:description content="Extract and format Markdown documentation from Python code."><meta property=og:image content=https://source.unsplash.com/1600x900/?forest><link rel=canonical href=https://carnarez.github.io/astdocs><link rel=icon href=# type=image/png><link rel=stylesheet href=https://carnarez.github.io/astdocs/style.css><script>function setTheme(e){localStorage.setItem("theme",e),document.documentElement.className=e}function toggleTheme(){"light"===localStorage.getItem("theme")?setTheme("dark"):"dark"===localStorage.getItem("theme")?setTheme("dimmed"):setTheme("light")}"dark"===localStorage.getItem("theme")||!("theme"in localStorage)&&window.matchMedia("(prefers-color-scheme: dark)").matches?setTheme("dark"):"dimmed"===localStorage.getItem("theme")?setTheme("dimmed"):setTheme("light")</script><script>var timer;window.addEventListener("scroll",()=>{let e=document.querySelector("#scroller"),o=document.querySelector("#topbar"),r=document.querySelector("#toc"),i=document.querySelector("article");var t,l;0<e.getBoundingClientRect().top?(e.style.width="0",document.querySelectorAll("aside, article").forEach(e=>{var t=e.className.match(/visible-sidebar/)||"";0<t.length&&e.classList.remove(t)}),r.scrollTop=0):(t=window.scrollY-window.innerHeight,l=o.offsetHeight+i.offsetHeight-window.innerHeight,e.style.width=100*Math.min(t/l,1)+"%",null!==timer&&clearTimeout(timer),timer=setTimeout(()=>{var t=i.querySelectorAll("h1, h2, h3, h4, h5, h6");for(let e=0;e<t.length;e++)if(0<t[e].getBoundingClientRect().top-parseInt(getComputedStyle(document.documentElement).scrollMarginTop)-1){0===e?history.pushState({},"",window.location.pathname):history.pushState({},"","#"+t[e-1].id);break}r.querySelectorAll("a").forEach(e=>{var t=e.getAttribute("href");t.startsWith("#")&&(t===window.location.hash?(e.classList.add("active"),(e.offsetTop<r.scrollTop+o.offsetHeight||e.offsetTop>window.innerHeight-o.offsetHeight)&&(r.scrollTop=e.offsetTop-2*o.offsetHeight)):e.classList.remove("active"))})},150))}),window.onload=()=>{let r=document.querySelector("#topbar"),i=document.querySelector("#toc"),e=i.querySelectorAll("a"),l=window.location.pathname.replace(/^[/]|[/]$/g,""),t=window.location.hash,c=(e.forEach(e=>{e.setAttribute("onclick","toggleSidebar('#toc')")}),[]),o=[];e.forEach(e=>{(e.getAttribute("href").startsWith("#")?o:c).push(e)}),c.forEach((e,t)=>{var o;e.getAttribute("href").replace(/^[/]|[/]$/g,"")===l&&(e.classList.add("active"),(e.offsetTop<i.scrollTop+r.offsetHeight||e.offsetTop>window.innerHeight-r.offsetHeight)&&(i.scrollTop=e.offsetTop-2*r.offsetHeight),0<t&&(e=c[t-1],o=document.querySelector("#prev"),localStorage.setItem("prev-content",e.href),o.href=e.href,o.text=e.text),t<c.length-1)&&(o=c[t+1],e=document.querySelector("#next"),localStorage.setItem("next-content",o.href),e.href=o.href,e.text=o.text)}),o.forEach(e=>{e.getAttribute("href")===t?(e.classList.add("active"),(e.offsetTop<i.scrollTop+r.offsetHeight||e.offsetTop>window.innerHeight-r.offsetHeight)&&(i.scrollTop=e.offsetTop-2*r.offsetHeight)):e.classList.remove("active")})}</script><script>window.addEventListener("keyup",e=>{var t=document.querySelector("#scroller"),o=e.key;0===t.getBoundingClientRect().top&&"BODY"===e.srcElement.tagName&&("<"===o?window.location.href=localStorage.getItem("prev-content")||"":">"===o?window.location.href=localStorage.getItem("next-content")||"":"."===o?toggleSidebar("#toc"):"?"===o&&toggleSidebar("#search")),"INPUT"===e.srcElement.tagName&&"Escape"===o&&e.srcElement.blur()})</script><script>function toggleSidebar(e,s=void 0){var i=document.querySelector("#scroller"),o=document.querySelector("aside"+e),e=document.querySelector(`aside:not(${e})`),l=document.querySelector("article");0<i.offsetTop&&window.scroll(0,i.offsetTop),e.classList.contains("visible-sidebar")&&(e.classList.remove("visible-sidebar"),l.classList.remove("visible-sidebar")),o.classList.contains("visible-sidebar")?(o.classList.remove("visible-sidebar"),l.classList.remove("visible-sidebar"),s=void 0):(o.classList.add("visible-sidebar"),l.classList.add("visible-sidebar")),void 0!==s?document.querySelector(s).focus():document.activeElement.blur()}</script><script>function lunrSearch(){fetch("https://carnarez.github.io/astdocs/index.json").then(e=>e.json()).then(e=>{let t=e.documents,a=lunr.Index.load(e.indexed),o=[],r=document.querySelector("#search-input").value,c=document.querySelector("#search-output");2<r.length?(c.innerHTML=`<li>No results for "<i>${r}</i>" in current corpus.</li>`,a.search(r).forEach(r=>{let e=t[r.ref][0],c=t[r.ref][1],n=t[r.ref][2],s=parseFloat(r.score).toFixed(3),l="";l=""===e?""!==c?"":"/":(""!==c?e+"/":e).replaceAll("/"," &gt; "),Object.keys(r.matchData.metadata).forEach(e=>{r.matchData.metadata[e].text.position.forEach(e=>{var t=document.createElement("li"),a=parseInt(e[0]),e=parseInt(e[1]);t.innerHTML=`
                      <a class="search-result" href="https://carnarez.github.io/astdocs/${r.ref}" onclick="toggleSidebar('#search')">
                        <div class="title">${l}${c}</div>
                        <div class="text">
                          ${n.slice(Math.max(0,a-100),a)}
                          <mark>${n.slice(a,a+e)}</mark>
                          ${n.slice(a+e,Math.min(a+e+100,n.length))}
                          <span class="score">${s}</span>
                        </div>
                      </a>
                    `,o.push(t)})})}),0<o.length&&c.replaceChildren(...o)):c.replaceChildren()})}function resetSearch(){var e=document.querySelector("#search-input"),t=document.querySelector("#search-output");e.value="",e.focus(),t.replaceChildren()}</script><script defer src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js onload=hljs.highlightAll()></script><script defer src=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.js></script><script defer src=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/contrib/auto-render.min.js onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})'></script><script defer src=https://cdnjs.cloudflare.com/ajax/libs/lunr.js/2.3.9/lunr.min.js></script><nav id=topbar><div><a class=sidebar onclick='toggleSidebar("#toc")'></a> <a class=search onclick='toggleSidebar("#search","#search-input")'></a> <span class=spacer></span> <span class=spacer></span> <a class=repo href=https://github.com/carnarez/astdocs></a> <a class=theme onclick=toggleTheme()></a></div></nav><header id=splash><img src=splash.svg> <span class=title>astdocs</span> <span class=description>Extract and format Markdown documentation from Python code.</span></header><nav id=scroller></nav><main><aside id=toc><div class=toc><ul><li><a href=#module-astdocs>Module astdocs</a><ul><li><a href=#functions>Functions</a><ul><li><a href=#astdocsformat_docstring>astdocs.format_docstring</a><li><a href=#astdocsparse_annotation>astdocs.parse_annotation</a><li><a href=#astdocsparse_class>astdocs.parse_class</a><li><a href=#astdocsparse_function>astdocs.parse_function</a><li><a href=#astdocsparse_import>astdocs.parse_import</a><li><a href=#astdocsparse>astdocs.parse</a><li><a href=#astdocsrender_class>astdocs.render_class</a><li><a href=#astdocsrender_function>astdocs.render_function</a><li><a href=#astdocsrender_module>astdocs.render_module</a><li><a href=#astdocsrender>astdocs.render</a><li><a href=#astdocsrender_recursively>astdocs.render_recursively</a><li><a href=#astdocspostrender>astdocs.postrender</a><li><a href=#astdocscli>astdocs.cli</a></ul></ul></ul></div></aside><aside id=search><header><a class=search onclick='document.querySelector("#search-input").focus()'></a> <input autocomplete=off id=search-input onkeyup=lunrSearch() placeholder="search with lunr"> <a class=reset onclick=resetSearch()></a></header><ul id=search-output></ul></aside><article><div><h1 id=module-astdocs>Module <code>astdocs</code></h1><p>Extract and format <code>Markdown</code> documentation from <code>Python</code> code.<p><em>According to</em> <strong>my</strong> <em>standards.</em><p>In a few more words, parse the underlying Abstract Syntax Tree (AST) description. (See the <a href=https://docs.python.org/3/library/ast.html>documentation</a> of the standard library module with same name.) It expects a relatively clean input (demonstrated in this very script) which forces <em>me</em> to keep <em>my</em> code somewhat correctly documented and without fancy syntax.<p>My only requirement was to use the <code>Python</code> standard library <strong>exclusively</strong> (even the <a href=https://docs.python.org/3/library/string.html#template-strings>templating</a>) as it is quite [overly] complete these days, and keep it as <em>lean</em> as possible. Support for corner cases is scarse...<p>The simplest way to check the output of this script is to run it on itself:<pre class=highlight><code class=language-shell>$ python astdocs.py astdocs.py  # pipe it to your favourite markdown linter</code></pre><p>or even:<pre class=highlight><code class=language-shell>$ python astdocs.py .  # recursively look for *.py files in the current directory</code></pre><p>The behaviour of this little stunt can be modified via environment variables:<ul><li><code>ASTDOCS_BOUND_OBJECTS</code> taking the <code>1</code>, <code>on</code>, <code>true</code> or <code>yes</code> values (anything else will be ignored/counted as negative) to add <code>%%%START ...</code> and <code>%%%END ...</code> markers to indicate the beginning/end of an object (useful for further styling when rendering in <code>HTML</code> for example). <strong>Not to be mixed up with the <code>%%%BEGIN</code> markers</strong> (see below).<li><code>ASTDOCS_FOLD_ARGS_AFTER</code> to fold long object (function/method) definitions (many parameters). Defaults to 88 characters, <a href=https://github.com/psf/black><code>black</code></a> <a href="https://www.youtube.com/watch?v=wf-BqAjZb8M&amp;t=260s&amp;ab_channel=PyCon2015">recommended</a> default.<li><code>ASTDOCS_SHOW_PRIVATE</code> taking the <code>1</code>, <code>on</code>, <code>true</code> or <code>yes</code> values (anything else will be ignored) to show <code>Python</code> private objects (which names start with an underscore).<li><code>ASTDOCS_SPLIT_BY</code> taking the <code>m</code>, <code>mc</code>, <code>mfc</code> or an empty value (default, all rendered content in one output): split each <strong>m</strong>odule, <strong>f</strong>unction and/or <strong>c</strong>lass (by adding <code>%%%BEGIN ...</code> markers). Classes will always keep their methods. In case <code>mfc</code> is provided, the module will only keep its docstring, and each function/class/method will be marked.<li><code>ASTDOCS_WITH_LINENOS</code> taking the <code>1</code>, <code>on</code>, <code>true</code> or <code>yes</code> values (anything else will be ignored) to show the line numbers of the object in the code source (to be processed later on by your favourite <code>Markdown</code> renderer). Look for the <code>%%%SOURCE ...</code> markers.</ul><pre class=highlight><code class=language-shell>$ ASTDOCS_WITH_LINENOS=on python astdocs.py astdocs.py</code></pre><p>or to split marked sections into separate files:<pre class=highlight><code class=language-shell>$ ASTDOCS_SPLIT_BY=mc python astdocs.py module.py | csplit -qz - '/^%%%BEGIN/' '{*}'
$ sed '1d' xx00 &gt; module.md
$ rm xx00
$ for f in xx??; do
&gt;   path=$(grep -m1 '^%%%BEGIN' $f | sed -r 's|%%%.* (.*)|\1|g;s|\.|/|g')
&gt;   mkdir -p $(dirname $path)
&gt;   sed '1d' $f &gt; "$path.md"  # double quotes are needed
&gt;   rm $f
&gt; done</code></pre><p>(See also the <code>Python</code> example in the docstring of the <code>astdocs.render_recursively()</code> function.)<p>Each of these environment variables translates into a configuration option stored in the <code>config</code> dictionnary of the present module. The key name is lowercased and stripped from the <code>ASTDOCS_</code> prefix.<p>When handling rendering programmatically one can use helper [private] functions (if necessary). See code and/or tests for details.<p>All encountered objects are stored as they are parsed. The content of the corresponding attribute can be used by external scripts to generate a dependency graph, or simply a Table of Contents:<pre class=highlight><code class=language-python>import astdocs

def toc(objects: dict[str, dict[str, dict[str, str]]]) -&gt; str:
    md = ""

    for m in objects:  # each module
        anchor = m.replace(".", "")  # github
        md += f"\n- [`{m}`](#module-{anchor})"
        for t in ["functions", "classes"]:  # relevant object types
            for o in objects[m][t]:
                anchor = (m + o).replace(".", "")  # github
                md += f"\n    - [`{m}.{o}`](#{anchor})"

    return md

md = astdocs.render_recursively(".")
toc = toc(astdocs.objects)

print(f"{toc}\n\n{md}")</code></pre><p><strong>Attributes</strong><ul><li><code>TPL</code> [<code>string.Template</code>]: Template to render the overall page (only governs order of objects in the output).<li><code>TPL_CLASSDEF</code> [<code>string.Template</code>]: Template to render <code>class</code> objects.<li><code>TPL_FUNCTIONDEF</code> [<code>string.Template</code>]: Template to render <code>def</code> objects (async or not).<li><code>TPL_MODULE</code> [<code>string.Template</code>]: Template to render the module summary.<li><code>objects</code> [<code>dict[str, typing.Any]</code>]: Nested dictionary of all relevant objects encountered while parsing the source code.</ul><p><strong>Functions</strong><ul><li><a href=#astdocsformat_docstring><code>format_docstring()</code></a>: Format the object docstring.<li><a href=#astdocsparse_annotation><code>parse_annotation()</code></a>: Format an annotation (object type or decorator).<li><a href=#astdocsparse_class><code>parse_class()</code></a>: Parse a <code>class</code> statement.<li><a href=#astdocsparse_function><code>parse_function()</code></a>: Parse a <code>def</code> statement.<li><a href=#astdocsparse_import><code>parse_import()</code></a>: Parse <code>import ... [as ...]</code> and <code>from ... import ... [as ...]</code> statements.<li><a href=#astdocsparse><code>parse()</code></a>: Recursively traverse the nodes of the abstract syntax tree.<li><a href=#astdocsrender_class><code>render_class()</code></a>: Render a <code>class</code> object, according to the defined <code>TPL_CLASSDEF</code> template.<li><a href=#astdocsrender_function><code>render_function()</code></a>: Render a <code>def</code> object (function or method).<li><a href=#astdocsrender_module><code>render_module()</code></a>: Render a module summary as a <code>Markdown</code> file.<li><a href=#astdocsrender><code>render()</code></a>: Run the whole pipeline (useful wrapper function when this gets used as a module).<li><a href=#astdocsrender_recursively><code>render_recursively()</code></a>: Run pipeline on each <code>Python</code> module found in a folder and its subfolders.<li><a href=#astdocspostrender><code>postrender()</code></a>: Apply a post-rendering function on the output of the decorated function.<li><a href=#astdocscli><code>cli()</code></a>: Process CLI calls.</ul><h2 id=functions>Functions</h2><h3 id=astdocsformat_docstring><code>astdocs.format_docstring</code></h3><pre class=highlight><code class=language-python>format_docstring(
    node: ast.AsyncFunctionDef | ast.ClassDef | ast.FunctionDef | ast.Module,
) -&gt; str:</code></pre><p>Format the object docstring.<p>Expect some stiff <code>NumPy</code>-ish formatting (see <a href=https://numpydoc.readthedocs.io/en/latest/example.html#example>this</a> or <a href=https://sphinxcontrib-napoleon.readthedocs.io/en/latest/example_numpy.html>that</a>). Do try to <strong>type</strong> all your input parameters/returned objects. And use a linter on the output?<p><strong>Parameters</strong><ul><li><code>node</code> [<code>ast.AsyncFunctionDef | ast.ClassDef | ast.FunctionDef | ast.Module</code>]: Source node to extract/parse docstring from.</ul><p><strong>Returns</strong><ul><li>[<code>str</code>]: The formatted docstring.</ul><p><strong>Example</strong><p>Below the raw docstring example of what this very function is expecting as an input (very inceptional):<pre class=highlight><code class=language-text>
Parameters
----------
node : ast.AsyncFunctionDef | ast.ClassDef | ast.FunctionDef | ast.Module
    Source node to extract/parse docstring from.

Returns
-------
: str
    The formatted docstring.</code></pre><p>The code blocks are extracted and replaced by placeholders before performing the substitutions (then rolled back in). The regular expressions are then applied:<ul><li>Leading hashtags (<code>#</code>) are removed from any lines starting with them as we do not want to conflict with the <code>Markdown</code> output.<li>Any series of words followed by a line with 3 or more hyphens is assumed to be a section marker (such as <code>Parameters</code>, <code>Returns</code>, <code>Example</code>, <em>etc.</em>).<li>Lines with <code>parameter : type</code> (<code>: type</code> optional) followed by a description, itself preceded by four spaces are formatted as input parameters.<li>Lines with <code>: type</code> (providing a type is here <em>mandatory</em>) followed by a description, itself preceded by four spaces are formatted as returned values.</ul><p>Keep in mind that returning <strong>the full path</strong> to a returned object is always preferable. And indeed <strong>some of it could be inferred</strong> from the function call itself, or the <code>return</code> statement. BUT this whole thing is to force <em>myself</em> to structure <em>my</em> docstrings correctly.<p><strong>Notes</strong><p>If the regular expression solution used here (which works for <em>my</em> needs) does not fulfill your standards, it is pretty easy to clobber it:<pre class=highlight><code class=language-python>import ast
import astdocs

def my_docstring_parser(docstring: str) -&gt; str:
    # process docstring
    return string

def format_docstring(node: ast.*) -&gt; str:  # simple wrapper function
    return my_docstring_parser(ast.get_docstring(node))

astdocs.format_docstring = format_docstring

print(astdocs.render(...))</code></pre><p><strong>Known problem</strong><p>Overall naive, stiff and <em>very</em> opinionated (again, for <em>my</em> use).<details><summary>source</summary><pre class=highlight><code class=language-python>def format_docstring(
    node: ast.AsyncFunctionDef | ast.ClassDef | ast.FunctionDef | ast.Module,
) -&gt; str:
    r"""Format the object docstring.

    Expect some stiff `NumPy`-ish formatting (see
    [this](https://numpydoc.readthedocs.io/en/latest/example.html#example) or
    [that](https://sphinxcontrib-napoleon.readthedocs.io/en/latest/example_numpy.html)).
    Do try to **type** all your input parameters/returned objects. And use a linter on
    the output?

    Parameters
    ----------
    node : ast.AsyncFunctionDef | ast.ClassDef | ast.FunctionDef | ast.Module
        Source node to extract/parse docstring from.

    Returns
    -------
    : str
        The formatted docstring.

    Example
    -------
    Below the raw docstring example of what this very function is expecting as an input
    (very inceptional):

    ```text

    Parameters
    ----------
    node : ast.AsyncFunctionDef | ast.ClassDef | ast.FunctionDef | ast.Module
        Source node to extract/parse docstring from.

    Returns
    -------
    : str
        The formatted docstring.
    ```

    The code blocks are extracted and replaced by placeholders before performing the
    substitutions (then rolled back in). The regular expressions are then applied:

    * Leading hashtags (`#`) are removed from any lines starting with them as we do not
      want to conflict with the `Markdown` output.
    * Any series of words followed by a line with 3 or more hyphens is assumed to be a
      section marker (such as `Parameters`, `Returns`, `Example`, *etc.*).
    * Lines with `parameter : type` (`: type` optional) followed by a description,
      itself preceded by four spaces are formatted as input parameters.
    * Lines with `: type` (providing a type is here *mandatory*) followed by a
      description, itself preceded by four spaces are formatted as returned values.

    Keep in mind that returning **the full path** to a returned object is always
    preferable. And indeed **some of it could be inferred** from the function call
    itself, or the `return` statement. BUT this whole thing is to force *myself* to
    structure *my* docstrings correctly.

    Notes
    -----
    If the regular expression solution used here (which works for *my* needs) does not
    fulfill your standards, it is pretty easy to clobber it:

    ```python
    import ast
    import astdocs

    def my_docstring_parser(docstring: str) -&gt; str:
        # process docstring
        return string

    def format_docstring(node: ast.*) -&gt; str:  # simple wrapper function
        return my_docstring_parser(ast.get_docstring(node))

    astdocs.format_docstring = format_docstring

    print(astdocs.render(...))
    ```

    Known problem
    -------------
    Overall naive, stiff and *very* opinionated (again, for *my* use).

    """
    s = ast.get_docstring(node) or ""

    # extract code blocks, replace them by a placeholder
    blocks = []
    patterns = [f"([`]{{{i}}}.*?[`]{{{i}}})" for i in range(7, 2, -1)]
    i = 0
    for p in patterns:
        for m in re.finditer(p, s, flags=re.DOTALL):
            blocks.append(m.group(1))
            s = s.replace(m.group(1), f"%%%BLOCK{i}", 1)
            i += 1

    # remove trailing spaces
    s = re.sub(r" {1,}\n", r"\n", s)

    # rework any word preceded by one or more hashtag
    s = re.sub(r"\n#+\s*(.*)", r"\n**\1**", s)

    # rework any word followed by a line with 3 or more dashes
    s = re.sub(r"\n([A-Za-z ]+)\n-{3,}", r"\n**\1**\n", s)

    # rework list of arguments/descriptions (no types)
    s = re.sub(r"\n([A-Za-z0-9_]+)\n {2,}(.*)", r"\n* `\1`: \2", s)

    # rework list of arguments/types/descriptions
    s = re.sub(
        r"\n([A-Za-z0-9_]+) : ([A-Za-z0-9_\[\],\.| ]+)\n {2,}(.*)",
        r"\n* `\1` [`\2`]: \3",
        s,
    )

    # rework list of types/descriptions (return values)
    s = re.sub(r"\n: ([A-Za-z0-9_\[\],\.| ]+)\n {2,}(.*)", r"\n* [`\1`]: \2", s)

    # put the code blocks back in
    for i, b in enumerate(blocks):
        s = s.replace(f"%%%BLOCK{i}", b)

    return s.strip()</code></pre></details><h3 id=astdocsparse_annotation><code>astdocs.parse_annotation</code></h3><pre class=highlight><code class=language-python>parse_annotation(a: typing.Any) -&gt; str:</code></pre><p>Format an annotation (object type or decorator).<p>Dive as deep as necessary within the children nodes until reaching the name of the module/attribute objects are annotated after; save the import path on the way. Recursively repeat for complicated object.<p>See the code itself for some line-by-line documentation.<p><strong>Parameters</strong><ul><li><code>a</code> [<code>typing.Any</code>]: The starting node to extract annotation information from.</ul><p><strong>Returns</strong><ul><li>[<code>str</code>]: The formatted annotation.</ul><p><strong>Known problems</strong><ul><li>The implementation only supports nodes I encountered in my projects.<li>Does not support <code>lambda</code> constructs.</ul><details><summary>source</summary><pre class=highlight><code class=language-python>def parse_annotation(a: typing.Any) -&gt; str:  # noqa: C901 (ignoring complexity warning)
    """Format an annotation (object type or decorator).

    Dive as deep as necessary within the children nodes until reaching the name of the
    module/attribute objects are annotated after; save the import path on the way.
    Recursively repeat for complicated object.

    See the code itself for some line-by-line documentation.

    Parameters
    ----------
    a : typing.Any
        The starting node to extract annotation information from.

    Returns
    -------
    : str
        The formatted annotation.

    Known problems
    --------------
    * The implementation only supports nodes I encountered in my projects.
    * Does not support `lambda` constructs.

    """
    s = ""

    # dig deeper: module.object
    if isinstance(a, ast.Attribute):
        s = f"{parse_annotation(a.value)}.{a.attr}"

    # dig deeper: | operator
    elif isinstance(a, ast.BinOp):
        s = parse_annotation(a.left)
        s += " | "
        s += parse_annotation(a.right)

    # dig deeper: @decorator(including=parameter)
    elif isinstance(a, ast.Call):
        s = parse_annotation(a.func)
        s += "("
        s += ", ".join([f"{a_.arg}={parse_annotation(a_.value)}" for a_ in a.keywords])
        s += ")"

    # we dug deep enough and unravelled a value
    elif isinstance(a, ast.Constant):
        s = f'"{a.value}"' if isinstance(a.value, str) else str(a.value)

    # dig deeper: content within a dictionnary
    elif isinstance(a, ast.Dict):
        s = "{"
        s += ", ".join(
            [
                f"{parse_annotation(k)}: {parse_annotation(v)}"
                for k, v in zip(a.keys, a.values, strict=True)
            ],
        )
        s += "}"

    # dig deeper: content within a list
    elif isinstance(a, ast.List):
        s = "["
        s += ", ".join([parse_annotation(a_) for a_ in a.elts])
        s += "]"

    # we dug deep enough and unravelled a canonical object
    elif isinstance(a, ast.Name):
        s = a.id

    # dig deeper: complex object, tuple[dict[int, float], bool, str] for instance
    elif isinstance(a, ast.Subscript):
        v = parse_annotation(a.slice)
        s = parse_annotation(a.value)
        s += "["
        s += v[1:-1] if v.startswith("(") and v.endswith(")") else v
        s += "]"

    # dig deeper: content within a set
    elif isinstance(a, ast.Set):
        s = "{"
        s += ", ".join([parse_annotation(a_) for a_ in a.elts])
        s += "}"

    # dig deeper: content within a tuple
    elif isinstance(a, ast.Tuple):
        s = "("
        s += ", ".join([parse_annotation(a_) for a_ in a.elts])
        s += ")"

    return s</code></pre></details><h3 id=astdocsparse_class><code>astdocs.parse_class</code></h3><pre class=highlight><code class=language-python>parse_class(
    node: ast.ClassDef,
    module: str,
    ancestry: str,
    classes: dict[str, dict[str, str]],
) -&gt; dict[str, dict[str, str]]:</code></pre><p>Parse a <code>class</code> statement.<p><strong>Parameters</strong><ul><li><code>node</code> [<code>ast.ClassDef</code>]: The node to extract information from.<li><code>module</code> [<code>str</code>]: Name of the current module.<li><code>ancestry</code> [<code>str</code>]: Complete path to the object, used to identify ownership of children objects (functions and methods for instance).<li><code>classes</code> [<code>dict[str, dict[str, str]]</code>]: Dictionnaries of all encountered class definitions.</ul><p><strong>Returns</strong><ul><li>[<code>dict[str, dict[str, str]]</code>]: Dictionnaries of all encountered class definitions.</ul><details><summary>source</summary><pre class=highlight><code class=language-python>def parse_class(
    node: ast.ClassDef,
    module: str,
    ancestry: str,
    classes: dict[str, dict[str, str]],
) -&gt; dict[str, dict[str, str]]:
    """Parse a `class` statement.

    Parameters
    ----------
    node : ast.ClassDef
        The node to extract information from.
    module : str
        Name of the current module.
    ancestry : str
        Complete path to the object, used to identify ownership of children objects
        (functions and methods for instance).
    classes : dict[str, dict[str, str]]
        Dictionnaries of all encountered class definitions.

    Returns
    -------
    : dict[str, dict[str, str]]
        Dictionnaries of all encountered class definitions.

    """
    ap = f"{ancestry}.{node.name}"  # absolute path to the object
    lp = ap.replace(module, "", 1).lstrip(".")  # local path to the object
    objects[module]["classes"][lp] = ap  # save the object path

    # parse decorator objects
    dc = [f"`@{parse_annotation(d)}`" for d in node.decorator_list]

    # save the object details
    classes[ap] = {
        "ancestry": ancestry,
        "classname": node.name,
        "classdocs": format_docstring(node),
        "decoration": "**Decoration** via " + ", ".join(dc) + "." if dc else "",
        "endlineno": str(node.end_lineno),
        "hashtags": "#" if "c" in config["split_by"] else "###",
        "lineno": str(node.lineno),
    }

    return classes</code></pre></details><h3 id=astdocsparse_function><code>astdocs.parse_function</code></h3><pre class=highlight><code class=language-python>parse_function(
    node: ast.AsyncFunctionDef | ast.FunctionDef,
    module: str,
    ancestry: str,
    functions: dict[str, dict[str, str]],
) -&gt; dict[str, dict]:</code></pre><p>Parse a <code>def</code> statement.<p><strong>Parameters</strong><ul><li><code>node</code> [<code>ast.AsyncFunctionDef | ast.FunctionDef</code>]: The node to extract information from.<li><code>module</code> [<code>str</code>]: Name of the current module.<li><code>ancestry</code> [<code>str</code>]: Complete path to the object, used to identify ownership of children objects (functions and methods for instance).<li><code>functions</code> [<code>dict[str, dict[str, str]]</code>]: Dictionnaries of all encountered function definitions.</ul><p><strong>Returns</strong><ul><li>[<code>dict[str, dict]</code>]: Dictionnaries of all encountered function definitions.</ul><p><strong>Notes</strong><p>If <code>*args</code> and some <code>kwargs</code> arguments are present, <code>args.vararg</code> will not be <code>None</code> and the <code>node.args.kwonlyargs</code> / <code>node.args.kw_defaults</code> attributes need to be parsed. Otherwise all should be available in the <code>args</code> / <code>defaults</code> attributes.<details><summary>source</summary><pre class=highlight><code class=language-python>def parse_function(
    node: ast.AsyncFunctionDef | ast.FunctionDef,
    module: str,
    ancestry: str,
    functions: dict[str, dict[str, str]],
) -&gt; dict[str, dict]:
    """Parse a `def` statement.

    Parameters
    ----------
    node : ast.AsyncFunctionDef | ast.FunctionDef
        The node to extract information from.
    module : str
        Name of the current module.
    ancestry : str
        Complete path to the object, used to identify ownership of children objects
        (functions and methods for instance).
    functions : dict[str, dict[str, str]]
        Dictionnaries of all encountered function definitions.

    Returns
    -------
    : dict[str, dict]
        Dictionnaries of all encountered function definitions.

    Notes
    -----
    If `*args` and some `kwargs` arguments are present, `args.vararg` will not be `None`
    and the `node.args.kwonlyargs` / `node.args.kw_defaults` attributes need to be
    parsed. Otherwise all should be available in the `args` / `defaults` attributes.

    """
    ap = f"{ancestry}.{node.name}"  # absolute path to the object
    lp = ap.replace(module, "", 1).lstrip(".")  # local path to the object
    objects[module]["functions"][lp] = ap  # save the object path

    params = []  # formatted function/method parameters

    # parse decorator objects
    dc = [f"`@{parse_annotation(d)}`" for d in node.decorator_list]

    # parse/format arguments and annotations; with default values if present
    def _parse_format_argument(ann: typing.Any, val: typing.Any = None) -&gt; str:
        """Parse and format an annotation.

        Parameters
        ----------
        ann : typing.Any
            Any type of annotation node.
        val : typing.Any
            Default value for this parameter.

        Returns
        -------
        : str
            Formatted annotation with potential default value.

        """
        s = ann.arg

        if ann.annotation is not None:
            s += ": "
            s += parse_annotation(ann.annotation)

        if val is not None:
            s += f" = {parse_annotation(val)}"

        return s

    # args; to accolate default values we need to reverse the argument list
    for ann, val in list(
        itertools.zip_longest(node.args.args[::-1], node.args.defaults[::-1]),
    )[::-1]:
        params.append(_parse_format_argument(ann, val))

    # *args
    if node.args.vararg is not None:
        params.append(f"*{node.args.vararg.arg}")

    # kwargs, only populated if args.vararg is; same accolation comment as above
    for ann, val in list(
        itertools.zip_longest(node.args.kwonlyargs[::-1], node.args.kw_defaults[::-1]),
    )[::-1]:
        params.append(_parse_format_argument(ann, val))

    # **kwargs
    if node.args.kwarg is not None:
        params.append(f"**{node.args.kwarg.arg}")

    # output
    output = f" -&gt; {parse_annotation(node.returns)}" if node.returns is not None else ""

    # add line breaks if the function call is long (pre-render this latter first, no way
    # around it)
    if len(f"{node.name}({', '.join(params)}){output}") &gt; config["fold_args_after"]:
        params = [f"\n    {p}" for p in params]
        suffix = ",\n"
    else:
        suffix = ""

    # save the object details
    functions[ap] = {
        "ancestry": ancestry,
        "params": ("," if suffix else ", ").join(params) + suffix,
        "decoration": ("**Decoration** via " + ", ".join(dc) + ".") if dc else "",
        "endlineno": str(node.end_lineno),
        "funcdocs": format_docstring(node),
        "funcname": node.name,
        "hashtags": "#" if "f" in config["split_by"] else "###",
        "lineno": str(node.lineno),
        "output": output,
    }

    return functions</code></pre></details><h3 id=astdocsparse_import><code>astdocs.parse_import</code></h3><pre class=highlight><code class=language-python>parse_import(
    node: ast.Import | ast.ImportFrom,
    module: str,
    ancestry: str,
    imports: dict[str, str],
) -&gt; dict[str, str]:</code></pre><p>Parse <code>import ... [as ...]</code> and <code>from ... import ... [as ...]</code> statements.<p>The content built by this function is currently <em>not</em> rendered. This latter is kept in case all the objects (and aliases) accessible within a module is required for a post-processing or some later [smart and exciting] implementations.<p><strong>Parameters</strong><ul><li><code>node</code> [<code>ast.Import | ast.ImportFrom</code>]: The node to extract information from.<li><code>module</code> [<code>str</code>]: Name of the current module.<li><code>ancestry</code> [<code>str</code>]: Complete path to the object, used to identify ownership of children objects (functions and methods for instance).<li><code>imports</code> [<code>dict[str, str] | None</code>]: Dictionnaries of parsed imports. Defaults to an empty dictionnary <code>{}</code>.</ul><p><strong>Returns</strong><ul><li>[<code>dict[str, str]</code>]: Dictionnaries of all encountered imports. Untouched for now, always empty dictionnary <code>{}</code>.</ul><details><summary>source</summary><pre class=highlight><code class=language-python>def parse_import(
    node: ast.Import | ast.ImportFrom,
    module: str,
    ancestry: str,
    imports: dict[str, str],
) -&gt; dict[str, str]:
    """Parse `import ... [as ...]` and `from ... import ... [as ...]` statements.

    The content built by this function is currently *not* rendered. This latter is kept
    in case all the objects (and aliases) accessible within a module is required for a
    post-processing or some later [smart and exciting] implementations.

    Parameters
    ----------
    node : ast.Import | ast.ImportFrom
        The node to extract information from.
    module : str
        Name of the current module.
    ancestry : str
        Complete path to the object, used to identify ownership of children objects
        (functions and methods for instance).
    imports : dict[str, str] | None
        Dictionnaries of parsed imports. Defaults to an empty dictionnary `{}`.

    Returns
    -------
    : dict[str, str]
        Dictionnaries of all encountered imports. Untouched for now, always empty
        dictionnary `{}`.

    """
    if isinstance(node, ast.Import):
        for n in node.names:
            abspath = f"{ancestry}.{n.name}"
            locpath = n.asname or n.name

            # save the object
            objects[module]["imports"][locpath] = abspath

    if isinstance(node, ast.ImportFrom):
        m = f"{node.module}." if node.module is not None else ""
        v = node.level + 1 if node.level &gt; 0 else 0
        for n in node.names:
            abspath = f"{ancestry}.{'.' * v}{m}{n.name}"
            locpath = n.asname or n.name

            # save the object; with support for heresy like "from .. import *" (who does
            # that seriously)
            objects[module]["imports"][locpath] = abspath

    return imports</code></pre></details><h3 id=astdocsparse><code>astdocs.parse</code></h3><pre class=highlight><code class=language-python>parse(
    node: typing.Any,
    module: str,
    ancestry: str = "",
    classes: dict[str, dict[str, str]] | None = None,
    functions: dict[str, dict[str, str]] | None = None,
    imports: dict[str, str] | None = None,
) -&gt; tuple[dict[str, dict[str, str]], dict[str, dict[str, str]], dict[str, str]]:</code></pre><p>Recursively traverse the nodes of the abstract syntax tree.<p>The present function calls the formatting function corresponding to the node name (if supported) to parse/format it.<p><strong>Parameters</strong><ul><li><code>node</code> [<code>typing.Any</code>]: Any type of node to extract information from.<li><code>module</code> [<code>str</code>]: Name of the current module.<li><code>ancestry</code> [<code>str</code>]: Complete path to the object, used to identify ownership of children objects (functions and methods for instance).<li><code>classes</code> [<code>dict[str, dict[str, str]] | None</code>]: Dictionnaries of parsed class definitions. Defaults to <code>None</code>.<li><code>functions</code> [<code>dict[str, dict[str, str]] | None</code>]: Dictionnaries of parsed function definitions. Defaults to <code>None</code>.<li><code>imports</code> [<code>dict[str, str] | None</code>]: Dictionnaries of parsed imports. Defaults to a <code>None</code>.</ul><p><strong>Returns</strong><ul><li>[<code>dict[str, dict[str, str]]</code>]: Dictionnaries of all encountered class definitions.<li>[<code>dict[str, dict[str, str]]</code>]: Dictionnaries of all encountered function definitions.<li>[<code>dict[str, str]</code>]: Dictionnaries of all encountered imports.</ul><details><summary>source</summary><pre class=highlight><code class=language-python>def parse(
    node: typing.Any,
    module: str,
    ancestry: str = "",
    classes: dict[str, dict[str, str]] | None = None,
    functions: dict[str, dict[str, str]] | None = None,
    imports: dict[str, str] | None = None,
) -&gt; tuple[dict[str, dict[str, str]], dict[str, dict[str, str]], dict[str, str]]:
    """Recursively traverse the nodes of the abstract syntax tree.

    The present function calls the formatting function corresponding to the node name
    (if supported) to parse/format it.

    Parameters
    ----------
    node : typing.Any
        Any type of node to extract information from.
    module : str
        Name of the current module.
    ancestry : str
        Complete path to the object, used to identify ownership of children objects
        (functions and methods for instance).
    classes : dict[str, dict[str, str]] | None
        Dictionnaries of parsed class definitions. Defaults to `None`.
    functions : dict[str, dict[str, str]] | None
        Dictionnaries of parsed function definitions. Defaults to `None`.
    imports : dict[str, str] | None
        Dictionnaries of parsed imports. Defaults to a `None`.

    Returns
    -------
    : dict[str, dict[str, str]]
        Dictionnaries of all encountered class definitions.
    : dict[str, dict[str, str]]
        Dictionnaries of all encountered function definitions.
    : dict[str, str]
        Dictionnaries of all encountered imports.

    """
    classes = {} if classes is None else classes
    functions = {} if functions is None else functions
    imports = {} if imports is None else imports

    for n in node.body:
        # call the parser for each supported node type
        if n.__class__.__name__ == "ClassDef":
            classes = parse_class(n, module, ancestry, classes)

        elif n.__class__.__name__ in ("AsyncFunctionDef", "FunctionDef"):
            functions = parse_function(n, module, ancestry, functions)

        elif n.__class__.__name__ in ("Import", "ImportFrom"):
            imports = parse_import(n, module, ancestry, imports)

        # not interested
        else:
            pass

        # recursively traverse the ast
        try:
            parse(
                n,
                module,
                f"{ancestry}.{n.name}",
                classes,
                functions,
                imports,
            )
        except AttributeError:
            continue

    return classes, functions, imports</code></pre></details><h3 id=astdocsrender_class><code>astdocs.render_class</code></h3><pre class=highlight><code class=language-python>render_class(
    filepath: str,
    name: str,
    classes: dict[str, dict[str, str]],
    functions: dict[str, dict[str, str]],
    config: dict[str, typing.Any] = config,
) -&gt; str:</code></pre><p>Render a <code>class</code> object, according to the defined <code>TPL_CLASSDEF</code> template.<p><strong>Parameters</strong><ul><li><code>filepath</code> [<code>str</code>]: Path to the module (file) defining the object.<li><code>name</code> [<code>str</code>]: The name (full path including all ancestors) of the object to render.<li><code>classes</code> [<code>dict[str, dict[str, str]]</code>]: Dictionnaries of all encountered class definitions.<li><code>functions</code> [<code>dict[str, dict[str, str]]</code>]: Dictionnaries of all encountered function definitions.<li><code>config</code> [<code>dict[str, typing.Any]</code>]: Configuration options used to render attributes.</ul><p><strong>Returns</strong><ul><li>[<code>str</code>]: <code>Markdown</code>-formatted description of the class object.</ul><details><summary>source</summary><pre class=highlight><code class=language-python>def render_class(
    filepath: str,
    name: str,
    classes: dict[str, dict[str, str]],
    functions: dict[str, dict[str, str]],
    config: dict[str, typing.Any] = config,
) -&gt; str:
    """Render a `class` object, according to the defined `TPL_CLASSDEF` template.

    Parameters
    ----------
    filepath : str
        Path to the module (file) defining the object.
    name : str
        The name (full path including all ancestors) of the object to render.
    classes : dict[str, dict[str, str]]
        Dictionnaries of all encountered class definitions.
    functions : dict[str, dict[str, str]]
        Dictionnaries of all encountered function definitions.
    config : dict[str, typing.Any]
        Configuration options used to render attributes.

    Returns
    -------
    : str
        `Markdown`-formatted description of the class object.

    """
    ht = classes[name]["hashtags"]

    # select related methods
    fs = [f for f in functions if f.startswith(f"{name}.")]

    # fetch the content of __init__
    n = f"{name}.__init__"
    if n in fs:
        fs.remove(n)
        details = functions.pop(n)
        params = re.sub(r"self[\s,]*", "", details["params"], count=1)
        docstring = details["funcdocs"]
        beglineno = details["lineno"]
        endlineno = details["endlineno"]
        if config["with_linenos"]:
            docstring += f"\n\n%%%SOURCE {filepath}:{beglineno}:{endlineno}"
    else:
        params = ""
        docstring = ""

    # methods rendered
    fsr = []
    for f in fs:
        n = f.split(".")[-1]
        if not n.startswith("_") or config["show_private"]:
            functions[f].update(
                {
                    "hashtags": f"{ht}##",
                    "params": re.sub(
                        r"self[\s,]*", "", functions[f]["params"], count=1
                    ),
                },
            )
            fsr.append(render_function(filepath, f, functions))

    # methods bullet list
    fsl = []
    for _i, f in enumerate(fs):
        n = f.split(".")[-1]
        if not n.startswith("_") or config["show_private"]:
            link = f.replace(".", "").lower()  # github syntax
            desc = functions[f]["funcdocs"].split("\n")[0]
            desc = f": {desc}" if len(desc) else ""
            fsl.append(f"* [`{n}()`](#{link}){desc}")

    # update the description of the object
    classes[name].update(
        {
            "params": params,
            "constdocs": docstring,
            "functions": (ht + "# Methods\n\n" + "\n\n".join(fsr)) if fsr else "",
            "funcnames": ("**Methods**\n\n" + "\n".join(fsl)) if fsl else "",
            "path": filepath,
        },
    )

    return TPL_CLASSDEF.substitute(classes[name]).strip()</code></pre></details><h3 id=astdocsrender_function><code>astdocs.render_function</code></h3><pre class=highlight><code class=language-python>render_function(filepath: str, name: str, functions: dict[str, dict[str, str]]) -&gt; str:</code></pre><p>Render a <code>def</code> object (function or method).<p>Follow the defined <code>TPL_FUNCTIONDEF</code> template.<p><strong>Parameters</strong><ul><li><code>filepath</code> [<code>str</code>]: Path to the module (file) defining the object.<li><code>name</code> [<code>str</code>]: The name (full path including all ancestors) of the object to render.<li><code>functions</code> [<code>dict[str, dict[str, str]]</code>]: Dictionnaries of all encountered function definitions.</ul><p><strong>Returns</strong><ul><li>[<code>str</code>]: <code>Markdown</code>-formatted description of the function/method object.</ul><details><summary>source</summary><pre class=highlight><code class=language-python>def render_function(
    filepath: str,
    name: str,
    functions: dict[str, dict[str, str]],
) -&gt; str:
    """Render a `def` object (function or method).

    Follow the defined `TPL_FUNCTIONDEF` template.

    Parameters
    ----------
    filepath : str
        Path to the module (file) defining the object.
    name : str
        The name (full path including all ancestors) of the object to render.
    functions : dict[str, dict[str, str]]
        Dictionnaries of all encountered function definitions.

    Returns
    -------
    : str
        `Markdown`-formatted description of the function/method object.

    """
    # update the description of the object
    functions[name].update({"path": filepath})

    return TPL_FUNCTIONDEF.substitute(functions[name]).strip()</code></pre></details><h3 id=astdocsrender_module><code>astdocs.render_module</code></h3><pre class=highlight><code class=language-python>render_module(
    name: str,
    docstring: str,
    classes: dict[str, dict[str, str]],
    functions: dict[str, dict[str, str]],
    config: dict[str, typing.Any] = config,
) -&gt; str:</code></pre><p>Render a module summary as a <code>Markdown</code> file.<p>Follow the defined <code>TPL_MODULE</code> template.<p><strong>Parameters</strong><ul><li><code>name</code> [<code>str</code>]: Name of the module being parsed.<li><code>docstring</code> [<code>str</code>]: The docstring of the module itself, if present (defaults to an empty string).<li><code>classes</code> [<code>dict[str, dict[str, str]]</code>]: Dictionnaries of all encountered class definitions.<li><code>functions</code> [<code>dict[str, dict[str, str]]</code>]: Dictionnaries of all encountered function definitions.<li><code>config</code> [<code>dict[str, typing.Any]</code>]: Configuration options used to render attributes.</ul><p><strong>Returns</strong><ul><li>[<code>str</code>]: <code>Markdown</code>-formatted description of the whole module.</ul><details><summary>source</summary><pre class=highlight><code class=language-python>def render_module(
    name: str,
    docstring: str,
    classes: dict[str, dict[str, str]],
    functions: dict[str, dict[str, str]],
    config: dict[str, typing.Any] = config,
) -&gt; str:
    """Render a module summary as a `Markdown` file.

    Follow the defined `TPL_MODULE` template.

    Parameters
    ----------
    name : str
        Name of the module being parsed.
    docstring : str
        The docstring of the module itself, if present (defaults to an empty string).
    classes : dict[str, dict[str, str]]
        Dictionnaries of all encountered class definitions.
    functions : dict[str, dict[str, str]]
        Dictionnaries of all encountered function definitions.
    config : dict[str, typing.Any]
        Configuration options used to render attributes.

    Returns
    -------
    : str
        `Markdown`-formatted description of the whole module.

    """
    # self-standing functions bullet list
    fs = []
    for f in functions:
        if f.count(".") == name.count(".") + 1:
            n = f.split(".")[-1]
            if not n.startswith("_") or config["show_private"]:
                link = f.replace(".", "").lower()  # github syntax
                desc = functions[f]["funcdocs"].split("\n")[0]
                desc = f": {desc}" if len(desc) else ""
                fs.append(f"* [`{n}()`](#{link}){desc}")

    # classes bullet list
    cs = []
    for c in classes:
        if c.count(".") == name.count(".") + 1:
            n = c.split(".")[-1]
            if not n.startswith("_") or config["show_private"]:
                link = c.replace(".", "").lower()  # github syntax
                desc = classes[c]["classdocs"].split("\n")[0]
                desc = f": {desc}" if len(desc) else ""
                cs.append(f"* [`{n}`](#{link}){desc}")

    sub = {
        "classnames": "**Classes**\n\n" + "\n".join(cs) if cs else "",
        "docstring": docstring,
        "funcnames": "**Functions**\n\n" + "\n".join(fs) if fs else "",
        "module": name,
    }

    # clean up the unwanted
    if "c" in config["split_by"]:
        sub["classnames"] = ""
    if "f" in config["split_by"]:
        sub["funcnames"] = ""

    return TPL_MODULE.substitute(sub).strip()</code></pre></details><h3 id=astdocsrender><code>astdocs.render</code></h3><pre class=highlight><code class=language-python>render(
    filepath: str = "",
    remove_from_path: str = "",
    code: str = "",
    module: str = "",
    config: dict[str, typing.Any] = config,
) -&gt; str:</code></pre><p>Run the whole pipeline (useful wrapper function when this gets used as a module).<p><strong>Parameters</strong><ul><li><code>filepath</code> [<code>str</code>]: The path to the module to process. Defaults to empty string.<li><code>remove_from_path</code> [<code>str</code>]: Part of the path to be removed. If one is rendering the content of a file buried deep down in a complicated folder tree <em>but</em> does not want this to appear in the ancestry of the module. Defaults to empty string.<li><code>code</code> [<code>str</code>]: Code to process; useful when used as a module. If both <code>filepath</code> and <code>code</code> are provided the latter will be ignored. Defaults to empty string.<li><code>module</code> [<code>str</code>]: Name of the current module. Defaults to empty string.<li><code>config</code> [<code>dict[str, typing.Any]</code>]: Configuration options used to render attributes.</ul><p><strong>Returns</strong><ul><li>[<code>str</code>]: <code>Markdown</code>-formatted content.</ul><details><summary>source</summary><pre class=highlight><code class=language-python>def render(
    filepath: str = "",
    remove_from_path: str = "",
    code: str = "",
    module: str = "",
    config: dict[str, typing.Any] = config,
) -&gt; str:
    """Run the whole pipeline (useful wrapper function when this gets used as a module).

    Parameters
    ----------
    filepath : str
        The path to the module to process. Defaults to empty string.
    remove_from_path : str
        Part of the path to be removed. If one is rendering the content of a file buried
        deep down in a complicated folder tree *but* does not want this to appear in the
        ancestry of the module. Defaults to empty string.
    code : str
        Code to process; useful when used as a module. If both `filepath` and `code` are
        provided the latter will be ignored. Defaults to empty string.
    module : str
        Name of the current module. Defaults to empty string.
    config : dict[str, typing.Any]
        Configuration options used to render attributes.

    Returns
    -------
    : str
        `Markdown`-formatted content.

    """
    _update_templates(config)

    if len(filepath):
        # clean up module name
        if remove_from_path:
            filepath = filepath.replace(remove_from_path, "")

        module = re.sub(r"\.py$", "", filepath.replace("/", ".")).lstrip(".")
        module = module.replace(".__init__", "")
        module = module if len(module) else str(pathlib.Path.cwd()).rsplit("/", 1)[-1]

        # traverse and parse the ast
        with pathlib.Path(filepath).open() as fp:
            n = ast.parse(fp.read())

    elif len(code) and len(module):
        filepath = f"{module}.py"
        n = ast.parse(code)

    else:
        return "Nothing to do."  # user provided nOthINg

    # all objects encountered over a whole run are kept track of
    global objects  # noqa: PLW0602
    objects[module] = {"classes": {}, "functions": {}, "imports": {}}

    # parse it all
    classes, functions, imports = parse(n, module, module, {}, {}, {})

    # render the functions at the root of the module
    fs = []
    for f in functions:
        if f.count(".") == module.count(".") + 1:
            name = f.split(".")[-1]
            if not name.startswith("_") or config["show_private"]:
                fs.append(render_function(filepath, f, functions))

    # render the classes at the root of the module
    cs = []
    for c in classes:
        if c.count(".") == module.count(".") + 1:
            name = c.split(".")[-1]
            if not name.startswith("_") or config["show_private"]:
                cs.append(render_class(filepath, c, classes, functions, config))

    # render each section according to provided options
    sub = {
        "classes": "\n\n".join(
            [
                "## Classes" if "c" not in config["split_by"] and cs else "",
                "\n\n".join(cs) if cs else "",
            ],
        ),
        "functions": "\n\n".join(
            [
                "## Functions" if "f" not in config["split_by"] and fs else "",
                "\n\n".join(fs) if fs else "",
            ],
        ),
        "module": render_module(
            module,
            format_docstring(n),
            classes,
            functions,
            config,
        ),
    }

    s = TPL.substitute(sub).strip()

    # cleanup (extra line breaks)
    s = re.sub(r"\n{3,}", "\n\n", s)
    return re.sub(r"\n{2,}%%%(^SOURCE[A-Z]*)", r"\n%%%\1", s)</code></pre></details><h3 id=astdocsrender_recursively><code>astdocs.render_recursively</code></h3><pre class=highlight><code class=language-python>render_recursively(
    path: str,
    remove_from_path: str = "",
    config: dict[str, typing.Any] = config,
) -&gt; str:</code></pre><p>Run pipeline on each <code>Python</code> module found in a folder and its subfolders.<p><strong>Parameters</strong><ul><li><code>path</code> [<code>str</code>]: The path to the folder to process.<li><code>remove_from_path</code> [<code>str</code>]: Part of the path to be removed.<li><code>config</code> [<code>dict[str, typing.Any]</code>]: Configuration options used to render attributes.</ul><p><strong>Returns</strong><ul><li>[<code>str</code>]: <code>Markdown</code>-formatted content for all <code>Python</code> modules within the path.</ul><p><strong>Example</strong><pre class=highlight><code class=language-python>import astdocs
import re

outdir = "docs"

for line in astdocs.render_recursively(...).split("\n"):
    if line.startswith("%%%BEGIN"):
        try:
            output.close()
        except NameError:
            pass
        path = re.sub(
            r"\.py$",
            ".md",
            "/".join([outdir.rstrip("/")] + line.split()[2].split(".")),
        )
        os.makedirs(path.split("/")[:-1], exist_ok=True)
        output = open(path, "w")
    else:
        output.write(f"{line}\n")
try:
    output.close()
except NameError:
    pass</code></pre><details><summary>source</summary><pre class=highlight><code class=language-python>def render_recursively(
    path: str,
    remove_from_path: str = "",
    config: dict[str, typing.Any] = config,
) -&gt; str:
    r"""Run pipeline on each `Python` module found in a folder and its subfolders.

    Parameters
    ----------
    path : str
        The path to the folder to process.
    remove_from_path : str
        Part of the path to be removed.
    config : dict[str, typing.Any]
        Configuration options used to render attributes.

    Returns
    -------
    : str
        `Markdown`-formatted content for all `Python` modules within the path.

    Example
    -------

    ```python
    import astdocs
    import re

    outdir = "docs"

    for line in astdocs.render_recursively(...).split("\n"):
        if line.startswith("%%%BEGIN"):
            try:
                output.close()
            except NameError:
                pass
            path = re.sub(
                r"\.py$",
                ".md",
                "/".join([outdir.rstrip("/")] + line.split()[2].split(".")),
            )
            os.makedirs(path.split("/")[:-1], exist_ok=True)
            output = open(path, "w")
        else:
            output.write(f"{line}\n")
    try:
        output.close()
    except NameError:
        pass
    ```

    """
    ms = []

    # render each module
    for filepath in sorted(pathlib.Path(path).glob("**/*.py")):
        name = str(filepath).split("/")[-1]
        if not name.startswith("_") or config["show_private"] or name == "__init__.py":
            ms.append(
                render(
                    filepath=str(filepath),
                    remove_from_path=remove_from_path,
                    config=config,
                ),
            )

    s = "\n\n".join(ms)

    # cleanup (extra line breaks)
    return re.sub(r"\n{2,}%%%(^SOURCE[A-Z]*)", r"\n%%%\1", s)</code></pre></details><h3 id=astdocspostrender><code>astdocs.postrender</code></h3><pre class=highlight><code class=language-python>postrender(func: typing.Callable) -&gt; typing.Callable:</code></pre><p>Apply a post-rendering function on the output of the decorated function.<p>This can be used to streamline the linting of the output, or immediately convert to <code>HTML</code> for instance.<p><strong>Parameters</strong><ul><li><code>func</code> [<code>typing.Callable</code>]: The function to apply; should take a <code>str</code> as lone input, the <code>Markdown</code> to process.</ul><p><strong>Returns</strong><ul><li>[<code>str</code>]: <code>Markdown</code>-formatted content.</ul><p><strong>Example</strong><p>Some general usage:<pre class=highlight><code class=language-python>import astdocs

def extend_that(md: str) -&gt; str:
    # process markdown
    return string

def apply_this(md: str) -&gt; str:
    # process markdown
    return string

@astdocs.postrender(extend_that)
@astdocs.postrender(apply_this)
def render(filepath: str) -&gt; str:  # simple wrapper function
    return astdocs.render(filepath)

print(render(...))</code></pre><p>or more concrete snippets, for instance lint the output immediately:<pre class=highlight><code class=language-python>import astdocs
import mdformat

def lint(md: str) -&gt; str:
    return mdformat.text(md)

@astdocs.postrender(lint)
def render(filepath: str) -&gt; str:
    return astdocs.render(filepath)

print(render(...))</code></pre><p>and replace the <code>%%%SOURCE ...</code> markers by <code>&lt;details&gt;</code> HTML tags including the code of each object:<pre class=highlight><code class=language-python>import astdocs
import re

def extract_snippet(md: str) -&gt; str:
    for m in re.finditer("^%%%SOURCE (.*):([0-9]+):([0-9]+)\n", md):
        ms = m.group(0)  # matched string
        fp, cs, ce = m.groups()  # path to module, first and last line of snippet
        with open(fp) as f:
            snippet = "\n".join(f.readlines()[cs:ce + 1])
        md = md.replace(
            ms, f"&lt;details&gt;&lt;summary&gt;Source&lt;/summary&gt;\n\n{snippet}\n\n&lt;/details&gt;"
        )
    return md

@astdocs.postrender(extract_snippet)
def render(filepath: str) -&gt; str:
    config = astdocs.config.copy()
    config.update({"with_linenos": True})
    return astdocs.render(filepath, config=config)

print(render(...))</code></pre><details><summary>source</summary><pre class=highlight><code class=language-python>def postrender(func: typing.Callable) -&gt; typing.Callable:
    r"""Apply a post-rendering function on the output of the decorated function.

    This can be used to streamline the linting of the output, or immediately convert to
    `HTML` for instance.

    Parameters
    ----------
    func : typing.Callable
        The function to apply; should take a `str` as lone input, the `Markdown` to
        process.

    Returns
    -------
    : str
        `Markdown`-formatted content.

    Example
    -------
    Some general usage:

    ```python
    import astdocs

    def extend_that(md: str) -&gt; str:
        # process markdown
        return string

    def apply_this(md: str) -&gt; str:
        # process markdown
        return string

    @astdocs.postrender(extend_that)
    @astdocs.postrender(apply_this)
    def render(filepath: str) -&gt; str:  # simple wrapper function
        return astdocs.render(filepath)

    print(render(...))
    ```

    or more concrete snippets, for instance lint the output immediately:

    ```python
    import astdocs
    import mdformat

    def lint(md: str) -&gt; str:
        return mdformat.text(md)

    @astdocs.postrender(lint)
    def render(filepath: str) -&gt; str:
        return astdocs.render(filepath)

    print(render(...))
    ```

    and replace the `%%%SOURCE ...` markers by `&lt;details&gt;` HTML tags including the code
    of each object:

    ```python
    import astdocs
    import re

    def extract_snippet(md: str) -&gt; str:
        for m in re.finditer("^%%%SOURCE (.*):([0-9]+):([0-9]+)\n", md):
            ms = m.group(0)  # matched string
            fp, cs, ce = m.groups()  # path to module, first and last line of snippet
            with open(fp) as f:
                snippet = "\n".join(f.readlines()[cs:ce + 1])
            md = md.replace(
                ms, f"&lt;details&gt;&lt;summary&gt;Source&lt;/summary&gt;\n\n{snippet}\n\n&lt;/details&gt;"
            )
        return md

    @astdocs.postrender(extract_snippet)
    def render(filepath: str) -&gt; str:
        config = astdocs.config.copy()
        config.update({"with_linenos": True})
        return astdocs.render(filepath, config=config)

    print(render(...))
    ```

    """

    def decorator(f: typing.Callable) -&gt; typing.Callable:
        def wrapper(*args: list, **kwargs: dict) -&gt; typing.Callable:
            return func(f(*args, **kwargs))

        return wrapper

    return decorator</code></pre></details><h3 id=astdocscli><code>astdocs.cli</code></h3><pre class=highlight><code class=language-python>cli() -&gt; None:</code></pre><p>Process CLI calls.<details><summary>source</summary><pre class=highlight><code class=language-python>def cli() -&gt; None:
    """Process CLI calls."""
    config = _update_configuration()

    if len(sys.argv) != 2:
        sys.exit("Wrong number of arguments! Accepting *one* only.")

    try:
        md = render(filepath=sys.argv[1], config=config)
    except IsADirectoryError:
        md = render_recursively(sys.argv[1], config=config)

    sys.stdout.write(f"{md}\n")</code></pre></details></div><span class=spacer></span><footer><a id=prev></a> <span class=spacer></span> <a id=next></a></footer></article></main>